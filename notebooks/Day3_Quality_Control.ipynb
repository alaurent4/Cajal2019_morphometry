{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 3. Quality control of the sample MRiShare dataset\n",
    "\n",
    "One of the most important yet least-standardized procedure is the **quality control** of your data. Every lab/researchers have their own method to check the quality of the acquired data and/or processing to make sure they are measuring what they intend to measure. While there is often no clear guideline about what should be checked, since it depends on the modality and processing, it can be classified into the two broad categories.\n",
    "\n",
    "1. QC on raw acquired data\n",
    "    * Does the image have intended FOV?\n",
    "    * Is there significant artefact/noise?\n",
    "    * Are there any abnormalities in the brain (incidental findings)?\n",
    "    --> If any problem is found, either exclude subject/data or keep them and see.\n",
    "    \n",
    "    \n",
    "2. QC on processed data\n",
    "    * Did processing go as intended?\n",
    "    e.g. Skull-stripping, registration, tissue segmentation...\n",
    "    --> If any problem is found, either exclude subject/data or modify the processing steps to resolve the issue.\n",
    "    \n",
    "The most important thing is to **look at your data** systematically, and save the results of any QC check you do in a spreadsheet.\n",
    "\n",
    "In addition to checking your data visually one by one, there are various QC metrics you can collect to find any outliers. For morphometric studies, the morphometric values themselves should be checked for the presence of any outliers. When you find outliers, you can go back to the image with outlier values to decide whether something went wrong in the processing or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systematically checking the individual images\n",
    "\n",
    "You can use the viewer of your choice to check all the images you have (both the raw images and after some processing), and that's what many labs do. But to make it more efficient, you can include a node in your pipeline that will take an image as input and produce a picture (saved as png file, for example) for every subject and for each processing that should be checked.\n",
    "\n",
    "In ABACI pipeline for MRiShare, we have many such nodes, and we also have a custom script to generate a web html pages that gather generated png files for viewing.\n",
    "\n",
    "One useful tool, in particular for checking **Freesurfer** processed results, is called visualQC (https://raamana.github.io/visualqc/). We will try this out on the processed Freesurfer data for the selected MRiShare subjects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!visualqc_freesurfer -i simple_sublist.txt -f /data/analyses/work_in_progress/freesurfer/fsmrishare-flair6.0 -o visQCtest -old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the distribution and outliers for QC and other metrics\n",
    "\n",
    "Any metric you collect as part of the analysis should be checked for any outliers. In addition, there are many other QC metrics proposed for structural and functional image processing, as listed here (http://preprocessed-connectomes-project.org/quality-assessment-protocol/).\n",
    "\n",
    "Here we will use both the morphometric data and some of the selected QC metric we computed for MRiShare subjects to see if there is any problematic subjects.\n",
    "\n",
    "**QC metrics**\n",
    "\n",
    "1) Tissue SNR\n",
    "\n",
    "    * computed as mean/sd in each tissue in each compartments\n",
    "\n",
    "2) Tissue CNR\n",
    "\n",
    "    * for T1 stats, WMGM (WM mean/GM mean)and GMCSF (GM mean/CSF mean)\n",
    "    * for T2flair stats, GMWM (GM mean/ WM mean) and GMCSF (GM mean/CSF mean)\n",
    "    \n",
    "3) Coregistration cost function\n",
    "\n",
    "**Morphometrics**\n",
    "\n",
    "1) SPM GM, WM, CSF volume\n",
    "\n",
    "2) Freesurfer global metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several python visualization packages that allows you to interactively inspect your data.\n",
    "\n",
    "Perhaps one of the most easiest one to use is **plotly_express** (https://medium.com/plotly/introducing-plotly-express-808df010143d), as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_dat_dir = '../data/'\n",
    "morph_dat = pd.read_csv(op.join(sample_dat_dir, 'sample_mrishare_morphometry.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(morph_dat, x=\"SPM_GM_Volume\", y=\"FS6_gm_T_vol\", hover_name=\"mrishare_id\", marginal_y=\"violin\",\n",
    "           marginal_x=\"box\", trendline=\"ols\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(morph_dat, y=\"volume\", x=\"measure\", color=\"measure\", box=True, points=\"all\", hover_data=stacked_hippRL.columns)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hippRL_vols = morph_dat[['mrishare_id', 'FS6_gm_R_hippo', 'FS6_gm_L_hippo']]\n",
    "hippRL_vols.set_index('mrishare_id', inplace = True)\n",
    "stacked_hippRL = hippRL_vols.stack()\n",
    "stacked_hippRL = stacked_hippRL.reset_index()\n",
    "stacked_hippRL.columns = ['mrishare_id', 'measure', 'volume']\n",
    "stacked_hippRL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(stacked_hippRL, y=\"volume\", color=\"measure\", box=True, points=\"all\", hover_data=stacked_hippRL.columns)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated files can be saved as a web html or image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.write_html(fig, 'FS6_hipp_dist.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
