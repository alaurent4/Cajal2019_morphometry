{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images as arrays\n",
    "\n",
    "When you scan a subject with MRI scanner, the images are first stored as **DICOM (Digital Imaging and Communications in Medicine)**.\n",
    "\n",
    "As you see in the description here (https://en.wikibooks.org/wiki/Neuroimaging_Data_Processing/DICOM), most neuroimaging software tools convert them to a lighter, eaier-to-work-with format, **NIFTI**. So the first step in any neuroimaging processing is to convert DICOM to NIFTI format, using toos such as **dcm2nii**.\n",
    "\n",
    "But reagardless of the file format, what you have to understand first is that images are simply **numerical arrays** that represent strength of a signal (i.e. intensity level) at a given point in space.\n",
    "\n",
    "To demonstrate this, we will construct an array using **numpy** package and visualize it with **matplotlib** in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Usage: fslmaths [-dt <datatype>] <first_input> [operations and inputs] <output> [-odt <datatype>]\r\n",
      "\r\n",
      "Datatype information:\r\n",
      " -dt sets the datatype used internally for calculations (default float for all except double images)\r\n",
      " -odt sets the output datatype ( default is float )\r\n",
      " Possible datatypes are: char short int float double input\r\n",
      " \"input\" will set the datatype to that of the original image\r\n",
      "\r\n",
      "Binary operations:\r\n",
      "  (some inputs can be either an image or a number)\r\n",
      " -add   : add following input to current image\r\n",
      " -sub   : subtract following input from current image\r\n",
      " -mul   : multiply current image by following input\r\n",
      " -div   : divide current image by following input\r\n",
      " -rem   : modulus remainder - divide current image by following input and take remainder\r\n",
      " -mas   : use (following image>0) to mask current image\r\n",
      " -thr   : use following number to threshold current image (zero anything below the number)\r\n",
      " -thrp  : use following percentage (0-100) of ROBUST RANGE to threshold current image (zero anything below the number)\r\n",
      " -thrP  : use following percentage (0-100) of ROBUST RANGE of non-zero voxels and threshold below\r\n",
      " -uthr  : use following number to upper-threshold current image (zero anything above the number)\r\n",
      " -uthrp : use following percentage (0-100) of ROBUST RANGE to upper-threshold current image (zero anything above the number)\r\n",
      " -uthrP : use following percentage (0-100) of ROBUST RANGE of non-zero voxels and threshold above\r\n",
      " -max   : take maximum of following input and current image\r\n",
      " -min   : take minimum of following input and current image\r\n",
      " -seed  : seed random number generator with following number\r\n",
      " -restart : replace the current image with input for future processing operations\r\n",
      " -save : save the current working image to the input filename\r\n",
      "\r\n",
      "Basic unary operations:\r\n",
      " -exp   : exponential\r\n",
      " -log   : natural logarithm\r\n",
      " -sin   : sine function\r\n",
      " -cos   : cosine function\r\n",
      " -tan   : tangent function\r\n",
      " -asin  : arc sine function\r\n",
      " -acos  : arc cosine function\r\n",
      " -atan  : arc tangent function\r\n",
      " -sqr   : square\r\n",
      " -sqrt  : square root\r\n",
      " -recip : reciprocal (1/current image)\r\n",
      " -abs   : absolute value\r\n",
      " -bin   : use (current image>0) to binarise\r\n",
      " -binv  : binarise and invert (binarisation and logical inversion)\r\n",
      " -fillh : fill holes in a binary mask (holes are internal - i.e. do not touch the edge of the FOV)\r\n",
      " -fillh26 : fill holes using 26 connectivity\r\n",
      " -index : replace each nonzero voxel with a unique (subject to wrapping) index number\r\n",
      " -grid <value> <spacing> : add a 3D grid of intensity <value> with grid spacing <spacing>\r\n",
      " -edge  : edge strength\r\n",
      " -tfce <H> <E> <connectivity>: enhance with TFCE, e.g. -tfce 2 0.5 6 (maybe change 6 to 26 for skeletons)\r\n",
      " -tfceS <H> <E> <connectivity> <X> <Y> <Z> <tfce_thresh>: show support area for voxel (X,Y,Z)\r\n",
      " -nan   : replace NaNs (improper numbers) with 0\r\n",
      " -nanm  : make NaN (improper number) mask with 1 for NaN voxels, 0 otherwise\r\n",
      " -rand  : add uniform noise (range 0:1)\r\n",
      " -randn : add Gaussian noise (mean=0 sigma=1)\r\n",
      " -inm <mean> :  (-i i ip.c) intensity normalisation (per 3D volume mean)\r\n",
      " -ing <mean> :  (-I i ip.c) intensity normalisation, global 4D mean)\r\n",
      " -range : set the output calmin/max to full data range\r\n",
      "\r\n",
      "Matrix operations:\r\n",
      " -tensor_decomp : convert a 4D (6-timepoint )tensor image into L1,2,3,FA,MD,MO,V1,2,3 (remaining image in pipeline is FA)\r\n",
      "\r\n",
      "Kernel operations (set BEFORE filtering operation if desired):\r\n",
      " -kernel 3D : 3x3x3 box centered on target voxel (set as default kernel)\r\n",
      " -kernel 2D : 3x3x1 box centered on target voxel\r\n",
      " -kernel box    <size>     : all voxels in a cube of width <size> mm centered on target voxel\r\n",
      " -kernel boxv   <size>     : all voxels in a cube of width <size> voxels centered on target voxel, CAUTION: size should be an odd number\r\n",
      " -kernel boxv3  <X> <Y> <Z>: all voxels in a cuboid of dimensions X x Y x Z centered on target voxel, CAUTION: size should be an odd number\r\n",
      " -kernel gauss  <sigma>    : gaussian kernel (sigma in mm, not voxels)\r\n",
      " -kernel sphere <size>     : all voxels in a sphere of radius <size> mm centered on target voxel\r\n",
      " -kernel file   <filename> : use external file as kernel\r\n",
      "\r\n",
      "Spatial Filtering operations: N.B. all options apart from -s use the default kernel or that _previously_ specified by -kernel\r\n",
      " -dilM    : Mean Dilation of non-zero voxels\r\n",
      " -dilD    : Modal Dilation of non-zero voxels\r\n",
      " -dilF    : Maximum filtering of all voxels\r\n",
      " -dilall  : Apply -dilM repeatedly until the entire FOV is covered\r\n",
      " -ero     : Erode by zeroing non-zero voxels when zero voxels found in kernel\r\n",
      " -eroF    : Minimum filtering of all voxels\r\n",
      " -fmedian : Median Filtering \r\n",
      " -fmean   : Mean filtering, kernel weighted (conventionally used with gauss kernel)\r\n",
      " -fmeanu  : Mean filtering, kernel weighted, un-normalised (gives edge effects)\r\n",
      " -s <sigma> : create a gauss kernel of sigma mm and perform mean filtering\r\n",
      " -subsamp2  : downsamples image by a factor of 2 (keeping new voxels centred on old)\r\n",
      " -subsamp2offc  : downsamples image by a factor of 2 (non-centred)\r\n",
      "\r\n",
      "Dimensionality reduction operations:\r\n",
      "  (the \"T\" can be replaced by X, Y or Z to collapse across a different dimension)\r\n",
      " -Tmean   : mean across time\r\n",
      " -Tstd    : standard deviation across time\r\n",
      " -Tmax    : max across time\r\n",
      " -Tmaxn   : time index of max across time\r\n",
      " -Tmin    : min across time\r\n",
      " -Tmedian : median across time\r\n",
      " -Tperc <percentage> : nth percentile (0-100) of FULL RANGE across time\r\n",
      " -Tar1    : temporal AR(1) coefficient (use -odt float and probably demean first)\r\n",
      "\r\n",
      "Basic statistical operations:\r\n",
      " -pval    : Nonparametric uncorrected P-value, assuming timepoints are the permutations; first timepoint is actual (unpermuted) stats image\r\n",
      " -pval0   : Same as -pval, but treat zeros as missing data\r\n",
      " -cpval   : Same as -pval, but gives FWE corrected P-values\r\n",
      " -ztop    : Convert Z-stat to (uncorrected) P\r\n",
      " -ptoz    : Convert (uncorrected) P to Z\r\n",
      " -rank    : Convert data to ranks (over T dim)\r\n",
      " -ranknorm: Transform to Normal dist via ranks\r\n",
      "\r\n",
      "Multi-argument operations:\r\n",
      " -roi <xmin> <xsize> <ymin> <ysize> <zmin> <zsize> <tmin> <tsize> : zero outside roi (using voxel coordinates). Inputting -1 for a size will set it to the full image extent for that dimension.\r\n",
      " -bptf  <hp_sigma> <lp_sigma> : (-t in ip.c) Bandpass temporal filtering; nonlinear highpass and Gaussian linear lowpass (with sigmas in volumes, not seconds); set either sigma<0 to skip that filter\r\n",
      " -roc <AROC-thresh> <outfile> [4Dnoiseonly] <truth> : take (normally binary) truth and test current image in ROC analysis against truth. <AROC-thresh> is usually 0.05 and is limit of Area-under-ROC measure FP axis. <outfile> is a text file of the ROC curve (triplets of values: FP TP threshold). If the truth image contains negative voxels these get excluded from all calculations. If <AROC-thresh> is positive then the [4Dnoiseonly] option needs to be set, and the FP rate is determined from this noise-only data, and is set to be the fraction of timepoints where any FP (anywhere) is seen, as found in the noise-only 4d-dataset. This is then controlling the FWE rate. If <AROC-thresh> is negative the FP rate is calculated from the zero-value parts of the <truth> image, this time averaging voxelwise FP rate over all timepoints. In both cases the TP rate is the average fraction of truth=positive voxels correctly found.\r\n",
      "\r\n",
      "Combining 4D and 3D images:\r\n",
      " If you apply a Binary operation (one that takes the current image and a new image together), when one is 3D and the other is 4D,\r\n",
      " the 3D image is cloned temporally to match the temporal dimensions of the 4D image.\r\n",
      "\r\n",
      "e.g. fslmaths inputVolume -add inputVolume2 output_volume\r\n",
      "     fslmaths inputVolume -add 2.5 output_volume\r\n",
      "     fslmaths inputVolume -add 2.5 -mul inputVolume2 output_volume\r\n",
      "\r\n",
      "     fslmaths 4D_inputVolume -Tmean -mul -1 -add 4D_inputVolume demeaned_4D_inputVolume\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!fslmaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_array = np.array([[ 0,  0,  0,  0,  0,  0,  0,  0],\n",
    "                     [ 0,  0,  0,  9, 99, 99, 94,  0],\n",
    "                     [ 0,  0,  0, 25, 99, 99, 79,  0],\n",
    "                     [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
    "                     [ 0,  0,  0, 56, 99, 99, 49,  0],\n",
    "                     [ 0,  0,  0, 73, 99, 99, 31,  0],\n",
    "                     [ 0,  0,  0, 91, 99, 99, 13,  0],\n",
    "                     [ 0,  0,  9, 99, 99, 94,  0,  0],\n",
    "                     [ 0,  0, 27, 99, 99, 77,  0,  0],\n",
    "                     [ 0,  0, 45, 99, 99, 59,  0,  0],\n",
    "                     [ 0,  0, 63, 99, 99, 42,  0,  0],\n",
    "                     [ 0,  0, 80, 99, 99, 24,  0,  0],\n",
    "                     [ 0,  1, 96, 99, 99,  6,  0,  0],\n",
    "                     [ 0, 16, 99, 99, 88,  0,  0,  0],\n",
    "                     [ 0,  0,  0,  0,  0,  0,  0,  0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the size of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show arrays as images using the plt.imshow command. This is the default output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(an_array)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the colormap to gray, but the choice is arbitrary. You can choose any color map you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(an_array, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIFTI image\n",
    "\n",
    "The above example is a small 2-dimensional array. Neuroimaging data are typically larger, and usually 3-D (anatomical image) or 4-D (3-D image with temporal axis).\n",
    "\n",
    "The NIFTI image contains three basic components:\n",
    " \n",
    "1. data array: this component is similar to an array above, except that it's 3-D or 4-D.\n",
    "2. header: this component stores various meta-data about the image, like resolution, image size, etc.\n",
    "3. affine: this component stores a transformation array that describes the relationship between data array and a reference space.\n",
    "\n",
    "The concept of affine is described in detail here (https://nipy.org/nibabel/coordinate_systems.html), but basically it allows us to relate numbers in the data array (i, j, k) to a reference space, usually either a \"real-world\" scanner space or a standard template space (right-left, anterior-posterior, superior-inferior).\n",
    "\n",
    "We can take a look at these components from the sample MRiShare data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_data_dir = '/data/ro_formateur/mrishare'\n",
    "my_data_dir = '/data/ishare'\n",
    "sample_T1 = op.join(my_data_dir, 'SHARE0001', 'anat', 'SHARE0001_T1w.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use nibabel package to load the sample T1 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_T1_img = nib.load(sample_T1)\n",
    "type(sample_T1_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the size of the image data directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_T1_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explore other attributes of this nibabel image object using tab completion after \"sample_T1_img\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_T1_img."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at each component listed above.\n",
    "\n",
    "First, we can access the data obj directly by img.dataobj or using method get_fdata().\n",
    "The only difference between the two is how they occupy computational memory. You can read more about this here (https://nipy.org/nibabel/images_and_memory.html), and here (https://nipy.org/nibabel/nibabel_images.html#proxies-caching) but in most cases you can use one or the other to access data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataobj = sample_T1_img.dataobj\n",
    "type(sample_dataobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataobj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value at approximate midpoint of the data\n",
    "sample_dataobj[128, 128, 91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = sample_T1_img.get_fdata()\n",
    "type(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data[128, 128, 91]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to take the mid-slice and look at it using plt.imshow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midslice_from_dataobj = sample_dataobj[:, :, 91]\n",
    "plt.imshow(midslice_from_dataobj, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_T1_img.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_T1_img.header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access individual entry of the heade information like in a Dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_T1_img.header['dim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the affine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_T1_img.affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since nibabel is not the only program that can read Nifti images, you can access similar information/metadata about the image using other commandline tools that comes with other software packages, like **fslhd** and **fslinfo** from FSL, **mri_info** from Freesurfer package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fslinfo {sample_T1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!fslhd {sample_T1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mri_info {sample_T1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, many packages have specialized visualization tools to let you look at Nifti images. Try opening both T1 and FLAIR image in the data folder using the following viewers:\n",
    "\n",
    "* FSLeyes: packaged with FSL\n",
    "* freeview: packaged with Freesurfer\n",
    "* MRIcron: standalone package\n",
    "\n",
    "\n",
    "## Surface-based image formats\n",
    "\n",
    "These are created when the volumetric image is processed to reconstruct a surface representation of the brain, as done by Freesurfer and other softwares. They are also essentially numerical arrays, but how this information is stored is different in different softwares. We will postpone examination of these formats until you learn about surface-based processing in the upcoming lectures.\n",
    "\n",
    "But here is the good overview of various formats and how to read them in nibabel (https://nben.net/MRI-Geometry/#cortical-surfaces).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
